{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "783e0b16",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-17T05:58:52.578660Z",
     "start_time": "2021-07-17T05:58:48.270523Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Amount of labels -> 101 \n",
      "\n",
      "CricketShot has the most samples with 167 clips\n",
      "PlayingViolin has the least samples with 100 clips\n",
      "\n",
      "All actions have: 25 samples\n",
      "\n",
      "Top 5 actions with least clips per sample:\n",
      "                Total Clips  Samples  Clips per sample\n",
      "Labels                                               \n",
      "PlayingViolin          100       25              4.00\n",
      "PullUps                100       25              4.00\n",
      "Skijet                 100       25              4.00\n",
      "TaiChi                 100       25              4.00\n",
      "BreastStroke           101       25              4.04 \n",
      "\n",
      "Top 5 actions with most clips per sample\n",
      "               Total Clips  Samples  Clips per sample\n",
      "Labels                                              \n",
      "CricketShot           167       25              6.68\n",
      "TennisSwing           166       25              6.64\n",
      "HorseRiding           164       25              6.56\n",
      "PlayingCello          164       25              6.56\n",
      "PlayingDhol           164       25              6.56\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'  # nopep8\n",
    "os.environ[\"TF_ENABLE_AUTO_MIXED_PRECISION\"] = '1'\n",
    "\n",
    "FILE_PATH = os.getcwd()\n",
    "import sys\n",
    "sys.path.append('\\\\'.join(FILE_PATH.split('\\\\')[:3]))\n",
    "import argparse\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.layers.experimental import preprocessing\n",
    "import pandas as pd\n",
    "from trainvaltest import trainvaltest\n",
    "\n",
    "tf.config.experimental.set_memory_growth(tf.config.list_physical_devices('GPU')[0], True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "655581ae",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-17T05:59:05.307153Z",
     "start_time": "2021-07-17T05:58:52.580654Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train:\n",
      "Found 205310 images belonging to 101 classes.\n",
      "Validation:\n",
      "Found 22758 images belonging to 101 classes.\n",
      "Test:\n",
      "Found 20267 images belonging to 101 classes.\n",
      "\n",
      "Input shape -> (240, 240, 3) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "MODEL_NAME = \"my_VGG16\"\n",
    "MODEL_PATH = f\"{MODEL_NAME}\"\n",
    "BATCH_SIZE = 8\n",
    "LABELS, INPUT_SHAPE, Train_Data, Val_Data, Test_Data = trainvaltest(BATCH_SIZE=BATCH_SIZE)\n",
    "EPOCHS = 20\n",
    "VERBOSE = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "992798db",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-17T05:59:05.322725Z",
     "start_time": "2021-07-17T05:59:05.309141Z"
    }
   },
   "outputs": [],
   "source": [
    "class Preprocess(layers.Layer):\n",
    "    def __init__(self, factor=0.2, scale=1.0 / 255.0, flipmode='horizontal', seed=182):\n",
    "        \"\"\"Image preprocessing layer Block\n",
    "\n",
    "        Args:\n",
    "            factor (float, optional): factor to set for rotation, brightness, zoom and image shifting. Defaults to 0.2.\n",
    "            scale (float, optional): float to multiple all features by and normalize tensorflow. Defaults to 1.0/255.0.\n",
    "            seed (int, optional): set the seed value for all preprocessing layers. Defaults to 182\n",
    "        \"\"\"\n",
    "        super(Preprocess, self).__init__()\n",
    "        self.factor = factor\n",
    "        self.scale = scale\n",
    "        self.seed = seed\n",
    "        self.flipmode = flipmode\n",
    "\n",
    "        self.rescale = preprocessing.Rescaling(scale=self.scale)\n",
    "        self.randomrotate = preprocessing.RandomRotation(factor=self.factor, seed=self.seed)\n",
    "        self.randomzoom = preprocessing.RandomZoom(height_factor=self.factor, width_factor=self.factor, seed=self.seed)\n",
    "        self.shift = preprocessing.RandomTranslation(height_factor=self.factor, width_factor=self.factor, seed=self.seed)\n",
    "        self.flip = preprocessing.RandomFlip(mode=self.flipmode, seed=self.seed)\n",
    "\n",
    "    @tf.function\n",
    "    def call(self, image):\n",
    "        \"\"\"apply all preprocessing steps in\n",
    "\n",
    "        Args:\n",
    "            image (tensor): numerical data of image\n",
    "\n",
    "        Returns:\n",
    "            tensor: preprocessed data\n",
    "        \"\"\"\n",
    "        image = self.rescale(image)\n",
    "        image = self.randomrotate(image)\n",
    "        image = self.randomzoom(image)\n",
    "        image = self.shift(image)\n",
    "        image = self.flip(image)\n",
    "        return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fabef3a3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-17T05:59:05.338727Z",
     "start_time": "2021-07-17T05:59:05.325725Z"
    }
   },
   "outputs": [],
   "source": [
    "def conv_layer(filters, kernel_size, padding, strides):\n",
    "    \"\"\"Creates a convolution layer for CNNBlock\n",
    "\n",
    "    Args:\n",
    "        filters (int): number of filters in conv layer\n",
    "        kernel_size (int): kernel size for conv layer\n",
    "        padding (str): either 'same' padding or 'valid' padding\n",
    "        strides (int): strides for conv layer\n",
    "\n",
    "    Returns:\n",
    "        conv layer: returns configured conv layer for CNNBlock\n",
    "    \"\"\"\n",
    "    layer = layers.Conv2D(filters=filters, kernel_size=kernel_size, padding=padding, strides=strides, activation=layers.ReLU())\n",
    "    return layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "57207248",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-17T05:59:05.354739Z",
     "start_time": "2021-07-17T05:59:05.340733Z"
    }
   },
   "outputs": [],
   "source": [
    "class CNNBlock(layers.Layer):\n",
    "    def __init__(self, filters, triple=False, conv_kernel_size=(3, 3), conv_strides=(1, 1), pool_size=(2, 2), pool_strides=(2, 2), padding='same'):\n",
    "        \"\"\"block of either double (or triple) conv layers\n",
    "\n",
    "        Args:\n",
    "            filters (int): numbers of filters for the conv layers within this block\n",
    "            triple (bool, optional): whether this conv block contains double (2) or triple (3) conv layers. Defaults to False.\n",
    "            conv_strides (tuple, optional): tuple to set strides value for conv layers. Defaults to (1, 1).\n",
    "            conv_kernel_size (tuple, optional): kernel size for the conv layers in this block. Defaults to (3, 3).\n",
    "            pool_size (tuple, optional): pool size for pooling layer for this block. Defaults to (2, 2).\n",
    "            pool_strides (tuple, optional): strides value for pooling for this block. Defaults to (2, 2).\n",
    "            padding (str, optional): padding value of conv layers. Defaults to 'same'.\n",
    "        \"\"\"\n",
    "        super(CNNBlock, self).__init__()\n",
    "        self.triple = triple\n",
    "        self.pool_size = pool_size\n",
    "        self.pool_strides = pool_strides\n",
    "        self.filters = filters\n",
    "        self.conv_kernel_size = conv_kernel_size\n",
    "        self.conv_strides = conv_strides\n",
    "        self.padding = padding\n",
    "\n",
    "        self.conv1 = conv_layer(filters=self.filters, kernel_size=self.conv_kernel_size, padding=self.padding, strides=self.conv_strides)\n",
    "        self.conv2 = conv_layer(filters=self.filters, kernel_size=self.conv_kernel_size, padding=self.padding, strides=self.conv_strides)\n",
    "        if self.triple == True:\n",
    "            self.conv3 = conv_layer(filters=self.filters, kernel_size=self.conv_kernel_size, padding=self.padding, strides=self.conv_strides)\n",
    "        self.bn = layers.BatchNormalization()\n",
    "        self.maxpooling = layers.MaxPooling2D(pool_size=self.pool_size, strides=self.pool_strides)\n",
    "\n",
    "    @tf.function\n",
    "    def call(self, input_tensor, training=False):\n",
    "        \"\"\"forward propagation\n",
    "\n",
    "        Args:\n",
    "            input_tensor (input_tensor): input tensor for this data point\n",
    "            training (bool): whether to set batch normalization to training or not\n",
    "\n",
    "        Returns:\n",
    "            tensor: output of the current CNN block\n",
    "        \"\"\"\n",
    "        x = self.conv1(input_tensor)\n",
    "        x = self.conv2(x)\n",
    "        if self.triple == True:\n",
    "            x = self.conv3(x)\n",
    "        x = self.bn(x, training=training)\n",
    "        x = self.maxpooling(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "34c7c16d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-17T05:59:05.369750Z",
     "start_time": "2021-07-17T05:59:05.356733Z"
    }
   },
   "outputs": [],
   "source": [
    "class Model(keras.Model):\n",
    "    def __init__(self, n_labels):\n",
    "        \"\"\"model build via subclassing\n",
    "\n",
    "        Args:\n",
    "            n_labels (int): amount of labels for the model to predict\n",
    "        \"\"\"\n",
    "        super(Model, self).__init__()\n",
    "        self.n_labels = n_labels\n",
    "\n",
    "        self.preprocess = Preprocess()\n",
    "        self.cnnblock1 = CNNBlock(filters=64)\n",
    "        self.cnnblock2 = CNNBlock(filters=128)\n",
    "        self.cnnblock3 = CNNBlock(filters=256, triple=True)\n",
    "        self.cnnblock4 = CNNBlock(filters=512, triple=True)\n",
    "        self.cnnblock5 = CNNBlock(filters=512, triple=True)\n",
    "        self.globalmaxpooling = layers.GlobalMaxPooling2D()\n",
    "        self.flatten = layers.Flatten()\n",
    "        self.fc = layers.Dense(4096, activation=layers.ReLU())\n",
    "        self.fc2 = layers.Dense(4096, activation=layers.ReLU())\n",
    "        self.outputs = layers.Dense(self.n_labels)\n",
    "\n",
    "    @tf.function\n",
    "    def call(self, input_tensor):\n",
    "        \"\"\"forward propagation for the entire model between each layer\n",
    "\n",
    "        Args:\n",
    "            input_tensor (tensor): output of the previous layer\n",
    "\n",
    "        Returns:\n",
    "            tensor: output of the previous tensor\n",
    "        \"\"\"\n",
    "        x = self.preprocess(input_tensor)\n",
    "        x = self.cnnblock1(x)\n",
    "        x = self.cnnblock2(x)\n",
    "        x = self.cnnblock3(x)\n",
    "        x = self.cnnblock4(x)\n",
    "        x = self.cnnblock5(x)\n",
    "        x = self.globalmaxpooling(x)\n",
    "        x = self.flatten(x)\n",
    "        x = self.fc(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.outputs(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "626b7829",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-17T05:59:05.385144Z",
     "start_time": "2021-07-17T05:59:05.370740Z"
    }
   },
   "outputs": [],
   "source": [
    "def create_model(inp_shape, n_labels, model_name, layer_names):\n",
    "    \"\"\"creates model (input and output), name layers and compile\n",
    "\n",
    "    Args:\n",
    "        inp_shape (tuple(int)): tuple of ints, input shape\n",
    "        n_labels (int): number of labels for last layer\n",
    "        model_name (str): name of model\n",
    "        layer_names (list(str)): list of names for each layer in model\n",
    "\n",
    "    Returns:\n",
    "        model: named and configured model with input/output and named layers\n",
    "    \"\"\"\n",
    "    model = Model(n_labels=n_labels)\n",
    "\n",
    "    for i, layer in enumerate(model.layers):\n",
    "        layer._name = layer_names[i]\n",
    "    model._name = model_name\n",
    "    model.build(input_shape=(None, *inp_shape))\n",
    "\n",
    "    model.compile(loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "                  optimizer=keras.optimizers.Adam(learning_rate=1e-4),\n",
    "                  metrics=[keras.metrics.SparseCategoricalAccuracy(name='acc')])\n",
    "\n",
    "    model.summary()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "892dc2b8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-17T05:59:05.401132Z",
     "start_time": "2021-07-17T05:59:05.387125Z"
    }
   },
   "outputs": [],
   "source": [
    "layer_names = tuple([\n",
    "    \"Preprocessing\",\n",
    "    \"CNNBlock64_Double\",\n",
    "    \"CNNBlock128_Double\",\n",
    "    \"CNNBlock256_Triple\",\n",
    "    \"CNNBlock512_Triple_1\",\n",
    "    \"CNNBlock512_Triple_2\",\n",
    "    \"GlobalMaxPooling\",\n",
    "    \"Flatten\",\n",
    "    \"FC\",\n",
    "    \"FC2\",\n",
    "    \"Outputs\"\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f6366c16",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-17T05:59:06.921241Z",
     "start_time": "2021-07-17T05:59:05.403129Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"my_VGG16\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "Preprocessing (Preprocess)   multiple                  0         \n",
      "_________________________________________________________________\n",
      "CNNBlock64_Double (CNNBlock) multiple                  38976     \n",
      "_________________________________________________________________\n",
      "CNNBlock128_Double (CNNBlock multiple                  221952    \n",
      "_________________________________________________________________\n",
      "CNNBlock256_Triple (CNNBlock multiple                  1476352   \n",
      "_________________________________________________________________\n",
      "CNNBlock512_Triple_1 (CNNBlo multiple                  5901824   \n",
      "_________________________________________________________________\n",
      "CNNBlock512_Triple_2 (CNNBlo multiple                  7081472   \n",
      "_________________________________________________________________\n",
      "GlobalMaxPooling (GlobalMaxP multiple                  0         \n",
      "_________________________________________________________________\n",
      "Flatten (Flatten)            multiple                  0         \n",
      "_________________________________________________________________\n",
      "FC (Dense)                   multiple                  2101248   \n",
      "_________________________________________________________________\n",
      "FC2 (Dense)                  multiple                  16781312  \n",
      "_________________________________________________________________\n",
      "Outputs (Dense)              multiple                  413797    \n",
      "=================================================================\n",
      "Total params: 34,016,933\n",
      "Trainable params: 34,013,989\n",
      "Non-trainable params: 2,944\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = create_model(inp_shape=INPUT_SHAPE, n_labels=LABELS, model_name=MODEL_NAME, layer_names=layer_names)\n",
    "earlystopping = keras.callbacks.EarlyStopping(monitor='val_acc', patience=3, verbose=VERBOSE)\n",
    "callbacks = [earlystopping]\n",
    "\n",
    "best_checkpoint = keras.callbacks.ModelCheckpoint(filepath=MODEL_PATH,\n",
    "                                                  monitor='val_acc',\n",
    "                                                  save_best_only=True,\n",
    "                                                  save_freq='epoch',\n",
    "                                                  verbose=VERBOSE)\n",
    "callbacks.append(best_checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4ca03087",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-17T08:29:42.298515Z",
     "start_time": "2021-07-17T05:59:06.924242Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "3208/3208 [==============================] - 2058s 639ms/step - loss: 3.8834 - acc: 0.1143 - val_loss: 3.7509 - val_acc: 0.1222\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.12218, saving model to my_VGG16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as conv2d_layer_call_fn, conv2d_layer_call_and_return_conditional_losses, conv2d_1_layer_call_fn, conv2d_1_layer_call_and_return_conditional_losses, conv2d_2_layer_call_fn while saving (showing 5 of 140). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: my_VGG16\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: my_VGG16\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/20\n",
      "3208/3208 [==============================] - 1966s 613ms/step - loss: 3.2580 - acc: 0.2082 - val_loss: 3.6279 - val_acc: 0.1694\n",
      "\n",
      "Epoch 00002: val_acc improved from 0.12218 to 0.16937, saving model to my_VGG16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as conv2d_layer_call_fn, conv2d_layer_call_and_return_conditional_losses, conv2d_1_layer_call_fn, conv2d_1_layer_call_and_return_conditional_losses, conv2d_2_layer_call_fn while saving (showing 5 of 140). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: my_VGG16\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: my_VGG16\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/20\n",
      "3208/3208 [==============================] - 1843s 575ms/step - loss: 2.7650 - acc: 0.3026 - val_loss: 3.4290 - val_acc: 0.2190\n",
      "\n",
      "Epoch 00003: val_acc improved from 0.16937 to 0.21901, saving model to my_VGG16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as conv2d_layer_call_fn, conv2d_layer_call_and_return_conditional_losses, conv2d_1_layer_call_fn, conv2d_1_layer_call_and_return_conditional_losses, conv2d_2_layer_call_fn while saving (showing 5 of 140). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: my_VGG16\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: my_VGG16\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/20\n",
      "3208/3208 [==============================] - 1892s 589ms/step - loss: 2.2542 - acc: 0.4197 - val_loss: 3.3871 - val_acc: 0.2306\n",
      "\n",
      "Epoch 00004: val_acc improved from 0.21901 to 0.23063, saving model to my_VGG16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as conv2d_layer_call_fn, conv2d_layer_call_and_return_conditional_losses, conv2d_1_layer_call_fn, conv2d_1_layer_call_and_return_conditional_losses, conv2d_2_layer_call_fn while saving (showing 5 of 140). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: my_VGG16\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: my_VGG16\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/20\n",
      "2101/3208 [==================>...........] - ETA: 10:34 - loss: 1.8543 - acc: 0.5133"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_13144/1152635295.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m train = model.fit(Train_Data,\n\u001b[0m\u001b[0;32m      2\u001b[0m                   \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mEPOCHS\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m                   \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mVERBOSE\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m                   \u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mTrain_Data\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m//\u001b[0m \u001b[0mBATCH_SIZE\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m                   \u001b[0mcallbacks\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1181\u001b[0m                 _r=1):\n\u001b[0;32m   1182\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1183\u001b[1;33m               \u001b[0mtmp_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1184\u001b[0m               \u001b[1;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1185\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    887\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    888\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 889\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    890\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    891\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    915\u001b[0m       \u001b[1;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    916\u001b[0m       \u001b[1;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 917\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=not-callable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    918\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    919\u001b[0m       \u001b[1;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   3021\u001b[0m       (graph_function,\n\u001b[0;32m   3022\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m-> 3023\u001b[1;33m     return graph_function._call_flat(\n\u001b[0m\u001b[0;32m   3024\u001b[0m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0;32m   3025\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1958\u001b[0m         and executing_eagerly):\n\u001b[0;32m   1959\u001b[0m       \u001b[1;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1960\u001b[1;33m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[0;32m   1961\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0;32m   1962\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[1;32m~\\miniconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    589\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    590\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 591\u001b[1;33m           outputs = execute.execute(\n\u001b[0m\u001b[0;32m    592\u001b[0m               \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    593\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     57\u001b[0m   \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 59\u001b[1;33m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[0;32m     60\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[0;32m     61\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train = model.fit(Train_Data,\n",
    "                  epochs=EPOCHS,\n",
    "                  verbose=VERBOSE,\n",
    "                  steps_per_epoch=len(Train_Data) // BATCH_SIZE,\n",
    "                  callbacks=callbacks,\n",
    "                  validation_data=Val_Data,\n",
    "                  validation_steps=len(Val_Data) // BATCH_SIZE,\n",
    "                  use_multiprocessing=True,\n",
    "                  workers=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cce4d5c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-17T08:29:42.301515Z",
     "start_time": "2021-07-17T08:29:42.301515Z"
    }
   },
   "outputs": [],
   "source": [
    "test = model.evaluate(Test_Data, steps=len(Test_Data) // BATCH_SIZE, workers=-1, use_multiprocessing=True, verbose=VERBOSE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4e08c5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_history = pd.DataFrame(train.history)\n",
    "train_history.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f0ebcd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 6))\n",
    "plt.title(\"Training\")\n",
    "def plotline(label):\n",
    "    return plt.plot(train_history[label], label=label, linestyle='--' if label[:3]=='val' else '-')\n",
    "\n",
    "for label in train_history.keys():\n",
    "    plotline(label=label)\n",
    "plt.xlabel('Epochs')\n",
    "plt.legend()\n",
    "plt.margins(x=0, y=0)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a11e632",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
