{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3fbe1d8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-22T15:23:09.833236Z",
     "start_time": "2021-07-22T15:22:50.059625Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'  # nopep8\n",
    "os.environ[\"TF_ENABLE_AUTO_MIXED_PRECISION\"] = '1'\n",
    "\n",
    "FILE_PATH = os.getcwd()\n",
    "import sys\n",
    "sys.path.append('\\\\'.join(FILE_PATH.split('\\\\')[:3]))\n",
    "import argparse\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.layers.experimental import preprocessing\n",
    "import pandas as pd\n",
    "from trainvaltest import trainvaltest\n",
    "\n",
    "tf.config.experimental.set_memory_growth(tf.config.list_physical_devices('GPU')[0], True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa09096f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-22T15:24:22.788797Z",
     "start_time": "2021-07-22T15:23:09.836236Z"
    }
   },
   "outputs": [],
   "source": [
    "MODEL_NAME = \"my_VGG19.h5\"\n",
    "MODEL_PATH = os.path.join(FILE_PATH, MODEL_NAME)\n",
    "BATCH_SIZE = 16\n",
    "LABELS, INPUT_SHAPE, Train_Data, Val_Data, Test_Data = trainvaltest(BATCH_SIZE=BATCH_SIZE)\n",
    "EPOCHS = 15\n",
    "VERBOSE = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3b5a165",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-22T15:24:22.804802Z",
     "start_time": "2021-07-22T15:24:22.790798Z"
    }
   },
   "outputs": [],
   "source": [
    "class Preprocess(layers.Layer):\n",
    "    def __init__(self, factor=0.2, scale=1.0 / 255.0, flipmode='horizontal', seed=182):\n",
    "        \"\"\"Image preprocessing layer Block\n",
    "\n",
    "        Args:\n",
    "            factor (float, optional): factor to set for rotation, brightness, zoom and image shifting. Defaults to 0.2.\n",
    "            scale (float, optional): float to multiple all features by and normalize tensorflow. Defaults to 1.0/255.0.\n",
    "            seed (int, optional): set the seed value for all preprocessing layers. Defaults to 182\n",
    "        \"\"\"\n",
    "        super(Preprocess, self).__init__()\n",
    "        self.factor = factor\n",
    "        self.scale = scale\n",
    "        self.seed = seed\n",
    "        self.flipmode = flipmode\n",
    "\n",
    "        self.rescale = preprocessing.Rescaling(scale=self.scale)\n",
    "        self.randomrotate = preprocessing.RandomRotation(factor=self.factor, seed=self.seed)\n",
    "        self.randomzoom = preprocessing.RandomZoom(height_factor=self.factor, width_factor=self.factor, seed=self.seed)\n",
    "        self.shift = preprocessing.RandomTranslation(height_factor=self.factor, width_factor=self.factor, seed=self.seed)\n",
    "        self.flip = preprocessing.RandomFlip(mode=self.flipmode, seed=self.seed)\n",
    "        \n",
    "    def get_config(self):\n",
    "        config = super().get_config().copy()\n",
    "        config.update({\n",
    "            'factor': self.factor,\n",
    "            'scale': self.scale,\n",
    "            'flipmode': self.flipmode,\n",
    "            'seed': self.seed\n",
    "        })\n",
    "        return config\n",
    "\n",
    "    @tf.function\n",
    "    def call(self, image):\n",
    "        \"\"\"apply all preprocessing steps in\n",
    "\n",
    "        Args:\n",
    "            image (tensor): numerical data of image\n",
    "\n",
    "        Returns:\n",
    "            tensor: preprocessed data\n",
    "        \"\"\"\n",
    "        image = self.rescale(image)\n",
    "        image = self.randomrotate(image)\n",
    "        image = self.randomzoom(image)\n",
    "        image = self.shift(image)\n",
    "        image = self.flip(image)\n",
    "        return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "949f4918",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-22T15:24:22.820806Z",
     "start_time": "2021-07-22T15:24:22.808802Z"
    }
   },
   "outputs": [],
   "source": [
    "class CNNBlock(layers.Layer):\n",
    "    def __init__(self, filters, quad=False, conv_kernel_size=(3, 3), conv_strides=(1, 1), pool_size=(2, 2), pool_strides=(2, 2), padding='same'):\n",
    "        \"\"\"block of either double (or triple) conv layers\n",
    "\n",
    "        Args:\n",
    "            filters (int): numbers of filters for the conv layers within this block\n",
    "            quad (bool, optional): whether this conv block contains double (2) or quadruple (4) conv layers. Defaults to False.\n",
    "            conv_strides (tuple, optional): tuple to set strides value for conv layers. Defaults to (1, 1).\n",
    "            conv_kernel_size (tuple, optional): kernel size for the conv layers in this block. Defaults to (3, 3).\n",
    "            pool_size (tuple, optional): pool size for pooling layer for this block. Defaults to (2, 2).\n",
    "            pool_strides (tuple, optional): strides value for pooling for this block. Defaults to (2, 2).\n",
    "            padding (str, optional): padding value of conv layers. Defaults to 'same'.\n",
    "        \"\"\"\n",
    "        super(CNNBlock, self).__init__()\n",
    "        self.quad = quad\n",
    "        self.pool_size = pool_size\n",
    "        self.pool_strides = pool_strides\n",
    "        self.filters = filters\n",
    "        self.conv_kernel_size = conv_kernel_size\n",
    "        self.conv_strides = conv_strides\n",
    "        self.padding = padding\n",
    "\n",
    "        self.conv1 = self.conv_layer()\n",
    "        self.conv2 = self.conv_layer()\n",
    "        if self.quad == True:\n",
    "            self.conv3 = self.conv_layer()\n",
    "            self.conv4 = self.conv_layer()\n",
    "        self.batch_norm = layers.BatchNormalization()\n",
    "        self.maxpooling = layers.MaxPooling2D(pool_size=self.pool_size, strides=self.pool_strides)\n",
    "        \n",
    "    def get_config(self):\n",
    "        config = super().get_config().copy()\n",
    "        config.update({\n",
    "            'quad': self.quad,\n",
    "            'pool_size': self.pool_size,\n",
    "            'pool_strides': self.pool_strides,\n",
    "            'filters': self.filters,\n",
    "            'conv_kernel_size': self.conv_kernel_size,\n",
    "            'conv_strides': self.conv_strides,\n",
    "            'padding': self.padding,\n",
    "        })\n",
    "        return config\n",
    "\n",
    "    def conv_layer(self):\n",
    "        return layers.Conv2D(filters=self.filters, kernel_size=self.conv_kernel_size, strides=self.conv_strides,\n",
    "                             padding=self.padding, activation=layers.ReLU(), use_bias=False, kernel_initializer='he_normal')\n",
    "\n",
    "    def __call__(self, input_tensor, training=False):\n",
    "        \"\"\"forward propagation\n",
    "\n",
    "        Args:\n",
    "            input_tensor (input_tensor): input tensor for this data point\n",
    "            training (bool): whether to set batch normalization to training or not\n",
    "\n",
    "        Returns:\n",
    "            tensor: output of the current CNN block\n",
    "        \"\"\"\n",
    "        x = self.conv1(input_tensor)\n",
    "        x = self.conv2(x)\n",
    "        if self.quad == True:\n",
    "            x = self.conv3(x)\n",
    "            x = self.conv4(x)\n",
    "        x = self.batch_norm(x, training=training)\n",
    "        x = self.maxpooling(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fcaa9b4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-22T15:24:22.836809Z",
     "start_time": "2021-07-22T15:24:22.822806Z"
    }
   },
   "outputs": [],
   "source": [
    "class Model(keras.Model):\n",
    "    def __init__(self, n_labels):\n",
    "        \"\"\"model build via subclassing\n",
    "\n",
    "        Args:\n",
    "            n_labels (int): amount of labels for the model to predict\n",
    "        \"\"\"\n",
    "        super(Model, self).__init__()\n",
    "        self.n_labels = n_labels\n",
    "\n",
    "        self.preprocess = Preprocess()\n",
    "        self.cnnblock1 = CNNBlock(filters=64)\n",
    "        self.cnnblock2 = CNNBlock(filters=128)\n",
    "        self.cnnblock3 = CNNBlock(filters=256, quad=True)\n",
    "        self.cnnblock4 = CNNBlock(filters=512, quad=True)\n",
    "        self.cnnblock5 = CNNBlock(filters=512, quad=True)\n",
    "        self.globalmaxpooling = layers.GlobalMaxPooling2D()\n",
    "        self.flatten = layers.Flatten()\n",
    "        self.fc = layers.Dense(4096, activation=layers.ReLU())\n",
    "        self.fc2 = layers.Dense(4096, activation=layers.ReLU())\n",
    "        self.outputs = layers.Dense(self.n_labels)\n",
    "\n",
    "    @tf.function\n",
    "    def call(self, input_tensor):\n",
    "        \"\"\"forward propagation for the entire model between each layer\n",
    "\n",
    "        Args:\n",
    "            input_tensor (tensor): output of the previous layer\n",
    "\n",
    "        Returns:\n",
    "            tensor: output of the previous tensor\n",
    "        \"\"\"\n",
    "        x = self.preprocess(input_tensor)\n",
    "        x = self.cnnblock1(x)\n",
    "        x = self.cnnblock2(x)\n",
    "        x = self.cnnblock3(x)\n",
    "        x = self.cnnblock4(x)\n",
    "        x = self.cnnblock5(x)\n",
    "        x = self.globalmaxpooling(x)\n",
    "        x = self.flatten(x)\n",
    "        x = self.fc(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.outputs(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75e3c2c5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-22T15:24:22.852812Z",
     "start_time": "2021-07-22T15:24:22.838809Z"
    }
   },
   "outputs": [],
   "source": [
    "def create_model(inp_shape, n_labels, model_name):\n",
    "    \"\"\"creates model (input and output), name layers and compile\n",
    "\n",
    "    Args:\n",
    "        inp_shape (tuple(int)): tuple of ints, input shape\n",
    "        n_labels (int): number of labels for last layer\n",
    "        model_name (str): name of model\n",
    "        layer_names (list(str)): list of names for each layer in model\n",
    "\n",
    "    Returns:\n",
    "        model: named and configured model with input/output and named layers\n",
    "    \"\"\"\n",
    "    model = keras.Sequential(Model(n_labels=n_labels).layers)    \n",
    "    model._name = model_name\n",
    "    model.build(input_shape=(None, *inp_shape))\n",
    "\n",
    "    model.compile(loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "                  optimizer=keras.optimizers.Adam(learning_rate=1e-4),\n",
    "                  metrics=[keras.metrics.SparseCategoricalAccuracy(name='acc')])\n",
    "\n",
    "    model.summary()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f6d917d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-22T15:24:24.600802Z",
     "start_time": "2021-07-22T15:24:22.854812Z"
    }
   },
   "outputs": [],
   "source": [
    "model = create_model(inp_shape=INPUT_SHAPE, n_labels=LABELS, model_name=MODEL_NAME)\n",
    "earlystopping = keras.callbacks.EarlyStopping(monitor='val_acc', patience=3, verbose=VERBOSE)\n",
    "callbacks = [earlystopping]\n",
    "\n",
    "best_checkpoint = keras.callbacks.ModelCheckpoint(filepath=MODEL_PATH,\n",
    "                                                  monitor='val_acc',\n",
    "                                                  save_best_only=True,\n",
    "                                                  save_freq='epoch',\n",
    "                                                  verbose=VERBOSE)\n",
    "callbacks.append(best_checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66c4adcc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-22T15:24:48.176432Z",
     "start_time": "2021-07-22T15:24:24.601802Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "train = model.fit(Train_Data,\n",
    "                  epochs=EPOCHS,\n",
    "                  verbose=VERBOSE,\n",
    "                  steps_per_epoch=len(Train_Data) // BATCH_SIZE,\n",
    "                  callbacks=callbacks,\n",
    "                  validation_data=Val_Data,\n",
    "                  validation_steps=len(Val_Data) // BATCH_SIZE,\n",
    "                  use_multiprocessing=True,\n",
    "                  workers=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e48c0940",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-22T15:24:48.177425Z",
     "start_time": "2021-07-22T15:24:48.177425Z"
    }
   },
   "outputs": [],
   "source": [
    "test = model.evaluate(Test_Data, steps=len(Test_Data) // BATCH_SIZE, workers=-1, use_multiprocessing=True, verbose=VERBOSE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21b4ce95",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-22T15:24:48.178435Z",
     "start_time": "2021-07-22T15:24:48.178435Z"
    }
   },
   "outputs": [],
   "source": [
    "train_history = pd.DataFrame(train.history)\n",
    "train_history.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d934cfa",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-22T15:24:48.179435Z",
     "start_time": "2021-07-22T15:24:48.179435Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 6))\n",
    "plt.title(\"Training\")\n",
    "def plotline(label):\n",
    "    return plt.plot(train_history[label], label=label, linestyle='--' if label[:3]=='val' else '-')\n",
    "\n",
    "for label in train_history.keys():\n",
    "    plotline(label=label)\n",
    "plt.xlabel('Epochs')\n",
    "plt.legend()\n",
    "plt.margins(x=0, y=0)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9555599d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
