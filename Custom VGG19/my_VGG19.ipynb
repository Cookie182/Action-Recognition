{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c3fbe1d8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-18T07:28:52.164734Z",
     "start_time": "2021-07-18T07:28:41.897106Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Amount of labels -> 101 \n",
      "\n",
      "CricketShot has the most samples with 167 clips\n",
      "PlayingViolin has the least samples with 100 clips\n",
      "\n",
      "All actions have: 25 samples\n",
      "\n",
      "Top 5 actions with least clips per sample:\n",
      "                Total Clips  Samples  Clips per sample\n",
      "Labels                                               \n",
      "PlayingViolin          100       25              4.00\n",
      "PullUps                100       25              4.00\n",
      "Skijet                 100       25              4.00\n",
      "TaiChi                 100       25              4.00\n",
      "BreastStroke           101       25              4.04 \n",
      "\n",
      "Top 5 actions with most clips per sample\n",
      "               Total Clips  Samples  Clips per sample\n",
      "Labels                                              \n",
      "CricketShot           167       25              6.68\n",
      "TennisSwing           166       25              6.64\n",
      "HorseRiding           164       25              6.56\n",
      "PlayingCello          164       25              6.56\n",
      "PlayingDhol           164       25              6.56\n",
      "\n",
      "train/test data already created\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'  # nopep8\n",
    "os.environ[\"TF_ENABLE_AUTO_MIXED_PRECISION\"] = '1'\n",
    "\n",
    "FILE_PATH = os.getcwd()\n",
    "import sys\n",
    "sys.path.append('\\\\'.join(FILE_PATH.split('\\\\')[:3]))\n",
    "import argparse\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.layers.experimental import preprocessing\n",
    "import pandas as pd\n",
    "from trainvaltest import trainvaltest\n",
    "\n",
    "tf.config.experimental.set_memory_growth(tf.config.list_physical_devices('GPU')[0], True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa09096f",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_NAME = \"my_VGG19\"\n",
    "MODEL_PATH = f\"{MODEL_NAME}\"\n",
    "BATCH_SIZE = 8\n",
    "LABELS, INPUT_SHAPE, Train_Data, Val_Data, Test_Data = trainvaltest(BATCH_SIZE=BATCH_SIZE)\n",
    "EPOCHS = 20\n",
    "VERBOSE = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3b5a165",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Preprocess(layers.Layer):\n",
    "    def __init__(self, factor=0.2, scale=1.0 / 255.0, flipmode='horizontal', seed=182):\n",
    "        \"\"\"Image preprocessing layer Block\n",
    "\n",
    "        Args:\n",
    "            factor (float, optional): factor to set for rotation, brightness, zoom and image shifting. Defaults to 0.2.\n",
    "            scale (float, optional): float to multiple all features by and normalize tensorflow. Defaults to 1.0/255.0.\n",
    "            seed (int, optional): set the seed value for all preprocessing layers. Defaults to 182\n",
    "        \"\"\"\n",
    "        super(Preprocess, self).__init__()\n",
    "        self.factor = factor\n",
    "        self.scale = scale\n",
    "        self.seed = seed\n",
    "        self.flipmode = flipmode\n",
    "\n",
    "        self.rescale = preprocessing.Rescaling(scale=self.scale)\n",
    "        self.randomrotate = preprocessing.RandomRotation(factor=self.factor, seed=self.seed)\n",
    "        self.randomzoom = preprocessing.RandomZoom(height_factor=self.factor, width_factor=self.factor, seed=self.seed)\n",
    "        self.shift = preprocessing.RandomTranslation(height_factor=self.factor, width_factor=self.factor, seed=self.seed)\n",
    "        self.flip = preprocessing.RandomFlip(mode=self.flipmode, seed=self.seed)\n",
    "\n",
    "    @tf.function\n",
    "    def call(self, image):\n",
    "        \"\"\"apply all preprocessing steps in\n",
    "\n",
    "        Args:\n",
    "            image (tensor): numerical data of image\n",
    "\n",
    "        Returns:\n",
    "            tensor: preprocessed data\n",
    "        \"\"\"\n",
    "        image = self.rescale(image)\n",
    "        image = self.randomrotate(image)\n",
    "        image = self.randomzoom(image)\n",
    "        image = self.shift(image)\n",
    "        image = self.flip(image)\n",
    "        return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbd6e394",
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_layer(filters, kernel_size, padding, strides):\n",
    "    \"\"\"Creates a convolution layer for CNNBlock\n",
    "\n",
    "    Args:\n",
    "        filters (int): number of filters in conv layer\n",
    "        kernel_size (int): kernel size for conv layer\n",
    "        padding (str): either 'same' padding or 'valid' padding\n",
    "        strides (int): strides for conv layer\n",
    "\n",
    "    Returns:\n",
    "        conv layer: returns configured conv layer for CNNBlock\n",
    "    \"\"\"\n",
    "    layer = layers.Conv2D(filters=filters, kernel_size=kernel_size, padding=padding, strides=strides, activation=layers.ReLU())\n",
    "    return layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "949f4918",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNNBlock(layers.Layer):\n",
    "    def __init__(self, filters, quad=False, conv_kernel_size=(3, 3), conv_strides=(1, 1), pool_size=(2, 2), pool_strides=(2, 2), padding='same'):\n",
    "        \"\"\"block of either double (or triple) conv layers\n",
    "\n",
    "        Args:\n",
    "            filters (int): numbers of filters for the conv layers within this block\n",
    "            quad (bool, optional): whether this conv block contains double (2) or quadruple (4) conv layers. Defaults to False.\n",
    "            conv_strides (tuple, optional): tuple to set strides value for conv layers. Defaults to (1, 1).\n",
    "            conv_kernel_size (tuple, optional): kernel size for the conv layers in this block. Defaults to (3, 3).\n",
    "            pool_size (tuple, optional): pool size for pooling layer for this block. Defaults to (2, 2).\n",
    "            pool_strides (tuple, optional): strides value for pooling for this block. Defaults to (2, 2).\n",
    "            padding (str, optional): padding value of conv layers. Defaults to 'same'.\n",
    "        \"\"\"\n",
    "        super(CNNBlock, self).__init__()\n",
    "        self.quad = quad\n",
    "        self.pool_size = pool_size\n",
    "        self.pool_strides = pool_strides\n",
    "        self.filters = filters\n",
    "        self.conv_kernel_size = conv_kernel_size\n",
    "        self.conv_strides = conv_strides\n",
    "        self.padding = padding\n",
    "\n",
    "        self.conv1 = conv_layer(filters=self.filters, kernel_size=self.conv_kernel_size, padding=self.padding, strides=self.conv_strides)\n",
    "        self.conv2 = conv_layer(filters=self.filters, kernel_size=self.conv_kernel_size, padding=self.padding, strides=self.conv_strides)\n",
    "        if self.quad == True:\n",
    "            self.conv3 = conv_layer(filters=self.filters, kernel_size=self.conv_kernel_size, padding=self.padding, strides=self.conv_strides)\n",
    "            self.conv4 = conv_layer(filters=self.filters, kernel_size=self.conv_kernel_size, padding=self.padding, strides=self.conv_strides)\n",
    "        self.bn = layers.BatchNormalization()\n",
    "        self.maxpooling = layers.MaxPooling2D(pool_size=self.pool_size, strides=self.pool_strides)\n",
    "\n",
    "    @tf.function\n",
    "    def call(self, input_tensor, training=False):\n",
    "        \"\"\"forward propagation\n",
    "\n",
    "        Args:\n",
    "            input_tensor (input_tensor): input tensor for this data point\n",
    "            training (bool): whether to set batch normalization to training or not\n",
    "\n",
    "        Returns:\n",
    "            tensor: output of the current CNN block\n",
    "        \"\"\"\n",
    "        x = self.conv1(input_tensor)\n",
    "        x = self.conv2(x)\n",
    "        if self.quad == True:\n",
    "            x = self.conv3(x)\n",
    "            x = self.conv4(x)\n",
    "        x = self.bn(x, training=training)\n",
    "        x = self.maxpooling(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fcaa9b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(keras.Model):\n",
    "    def __init__(self, n_labels):\n",
    "        \"\"\"model build via subclassing\n",
    "\n",
    "        Args:\n",
    "            n_labels (int): amount of labels for the model to predict\n",
    "        \"\"\"\n",
    "        super(Model, self).__init__()\n",
    "        self.n_labels = n_labels\n",
    "\n",
    "        self.preprocess = Preprocess()\n",
    "        self.cnnblock1 = CNNBlock(filters=64)\n",
    "        self.cnnblock2 = CNNBlock(filters=128)\n",
    "        self.cnnblock3 = CNNBlock(filters=256, quad=True)\n",
    "        self.cnnblock4 = CNNBlock(filters=512, quad=True)\n",
    "        self.cnnblock5 = CNNBlock(filters=512, quad=T\n",
    "                                  rue)\n",
    "        self.globalmaxpooling = layers.GlobalMaxPooling2D()\n",
    "        self.flatten = layers.Flatten()\n",
    "        self.fc = layers.Dense(4096, activation=layers.ReLU())\n",
    "        self.fc2 = layers.Dense(4096, activation=layers.ReLU())\n",
    "        self.outputs = layers.Dense(self.n_labels)\n",
    "\n",
    "    @tf.function\n",
    "    def call(self, input_tensor):\n",
    "        \"\"\"forward propagation for the entire model between each layer\n",
    "\n",
    "        Args:\n",
    "            input_tensor (tensor): output of the previous layer\n",
    "\n",
    "        Returns:\n",
    "            tensor: output of the previous tensor\n",
    "        \"\"\"\n",
    "        x = self.preprocess(input_tensor)\n",
    "        x = self.cnnblock1(x)\n",
    "        x = self.cnnblock2(x)\n",
    "        x = self.cnnblock3(x)\n",
    "        x = self.cnnblock4(x)\n",
    "        x = self.cnnblock5(x)\n",
    "        x = self.globalmaxpooling(x)\n",
    "        x = self.flatten(x)\n",
    "        x = self.fc(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.outputs(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75e3c2c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(inp_shape, n_labels, model_name, layer_names):\n",
    "    \"\"\"creates model (input and output), name layers and compile\n",
    "\n",
    "    Args:\n",
    "        inp_shape (tuple(int)): tuple of ints, input shape\n",
    "        n_labels (int): number of labels for last layer\n",
    "        model_name (str): name of model\n",
    "        layer_names (list(str)): list of names for each layer in model\n",
    "\n",
    "    Returns:\n",
    "        model: named and configured model with input/output and named layers\n",
    "    \"\"\"\n",
    "    model = Model(n_labels=n_labels)\n",
    "\n",
    "    for i, layer in enumerate(model.layers):\n",
    "        layer._name = layer_names[i]\n",
    "    model._name = model_name\n",
    "    model.build(input_shape=(None, *inp_shape))\n",
    "\n",
    "    model.compile(loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "                  optimizer=keras.optimizers.Adam(learning_rate=1e-4),\n",
    "                  metrics=[keras.metrics.SparseCategoricalAccuracy(name='acc')])\n",
    "\n",
    "    model.summary()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e966504d",
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_names = tuple([\n",
    "    \"Preprocessing\",\n",
    "    \"CNNBlock64_Double\",\n",
    "    \"CNNBlock128_Double\",\n",
    "    \"CNNBlock256_Triple\",\n",
    "    \"CNNBlock512_Triple_1\",\n",
    "    \"CNNBlock512_Triple_2\",\n",
    "    \"GlobalMaxPooling\",\n",
    "    \"Flatten\",\n",
    "    \"FC\",\n",
    "    \"FC2\",\n",
    "    \"Outputs\"\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f6d917d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = create_model(inp_shape=INPUT_SHAPE, n_labels=LABELS, model_name=MODEL_NAME, layer_names=layer_names)\n",
    "earlystopping = keras.callbacks.EarlyStopping(monitor='val_acc', patience=3, verbose=VERBOSE)\n",
    "callbacks = [earlystopping]\n",
    "\n",
    "best_checkpoint = keras.callbacks.ModelCheckpoint(filepath=MODEL_PATH,\n",
    "                                                  monitor='val_acc',\n",
    "                                                  save_best_only=True,\n",
    "                                                  save_freq='epoch',\n",
    "                                                  verbose=VERBOSE)\n",
    "callbacks.append(best_checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66c4adcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = model.fit(Train_Data,\n",
    "                  epochs=EPOCHS,\n",
    "                  verbose=VERBOSE,\n",
    "                  steps_per_epoch=len(Train_Data) // BATCH_SIZE,\n",
    "                  callbacks=callbacks,\n",
    "                  validation_data=Val_Data,\n",
    "                  validation_steps=len(Val_Data) // BATCH_SIZE,\n",
    "                  use_multiprocessing=True,\n",
    "                  workers=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e48c0940",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = model.evaluate(Test_Data, steps=len(Test_Data) // BATCH_SIZE, workers=-1, use_multiprocessing=True, verbose=VERBOSE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21b4ce95",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_history = pd.DataFrame(train.history)\n",
    "train_history.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d934cfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 6))\n",
    "plt.title(\"Training\")\n",
    "def plotline(label):\n",
    "    return plt.plot(train_history[label], label=label, linestyle='--' if label[:3]=='val' else '-')\n",
    "\n",
    "for label in train_history.keys():\n",
    "    plotline(label=label)\n",
    "plt.xlabel('Epochs')\n",
    "plt.legend()\n",
    "plt.margins(x=0, y=0)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9555599d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
