{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5ddca6d0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-16T05:55:36.835785Z",
     "start_time": "2021-07-16T05:55:26.667084Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Amount of labels -> 101 \n",
      "\n",
      "CricketShot has the most samples with 167 clips\n",
      "PlayingViolin has the least samples with 100 clips\n",
      "\n",
      "All actions have: 25 samples\n",
      "\n",
      "Top 5 actions with least clips per sample:\n",
      "                Total Clips  Samples  Clips per sample\n",
      "Labels                                               \n",
      "PlayingViolin          100       25              4.00\n",
      "PullUps                100       25              4.00\n",
      "Skijet                 100       25              4.00\n",
      "TaiChi                 100       25              4.00\n",
      "BreastStroke           101       25              4.04 \n",
      "\n",
      "Top 5 actions with most clips per sample\n",
      "               Total Clips  Samples  Clips per sample\n",
      "Labels                                              \n",
      "CricketShot           167       25              6.68\n",
      "TennisSwing           166       25              6.64\n",
      "HorseRiding           164       25              6.56\n",
      "PlayingCello          164       25              6.56\n",
      "PlayingDhol           164       25              6.56\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'  # nopep8\n",
    "os.environ[\"TF_ENABLE_AUTO_MIXED_PRECISION\"] = '1'\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.layers.experimental import preprocessing\n",
    "FILE_PATH = os.getcwd()\n",
    "import sys\n",
    "sys.path.append('\\\\'.join(FILE_PATH.split('\\\\')[:3]))\n",
    "import pandas as pd\n",
    "from trainvaltest import trainvaltest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "607ea6f9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-16T05:59:10.978960Z",
     "start_time": "2021-07-16T05:55:36.838803Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train:\n",
      "Found 205310 images belonging to 101 classes.\n",
      "Validation:\n",
      "Found 22758 images belonging to 101 classes.\n",
      "Test:\n",
      "Found 20267 images belonging to 101 classes.\n",
      "\n",
      "Input shape -> (240, 240, 3) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "tf.config.experimental.set_memory_growth(tf.config.list_physical_devices('GPU')[0], True)\n",
    "\n",
    "MODEL_NAME = \"the_first_war\"\n",
    "MODEL_PATH = f\"{MODEL_NAME}\"\n",
    "BATCH_SIZE = 16\n",
    "LABELS, INPUT_SHAPE, Train_Data, Val_Data, Test_Data = trainvaltest(BATCH_SIZE=BATCH_SIZE)\n",
    "EPOCHS = 30\n",
    "VERBOSE = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8083f159",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-16T05:59:10.994951Z",
     "start_time": "2021-07-16T05:59:10.980955Z"
    }
   },
   "outputs": [],
   "source": [
    "class Preprocess(layers.Layer):\n",
    "    def __init__(self, factor=0.2, scale=1.0 / 255.0, flipmode='horizontal', seed=182):\n",
    "        \"\"\"Image preprocessing layer Block\n",
    "\n",
    "        Args:\n",
    "            factor (float, optional): factor to set for rotation, brightness, zoom and image shifting. Defaults to 0.2.\n",
    "            scale (float, optional): float to multiple all features by and normalize tensorflow. Defaults to 1.0/255.0.\n",
    "            seed (int, optional): set the seed value for all preprocessing layers. Defaults to 182\n",
    "        \"\"\"\n",
    "        super(Preprocess, self).__init__()\n",
    "        self.factor = factor\n",
    "        self.scale = scale\n",
    "        self.seed = seed\n",
    "        self.flipmode = flipmode\n",
    "\n",
    "        self.rescale = preprocessing.Rescaling(scale=self.scale)\n",
    "        self.randomrotate = preprocessing.RandomRotation(factor=self.factor, seed=self.seed)\n",
    "        self.randomzoom = preprocessing.RandomZoom(height_factor=self.factor, width_factor=self.factor, seed=self.seed)\n",
    "        self.shift = preprocessing.RandomTranslation(height_factor=self.factor, width_factor=self.factor, seed=self.seed)\n",
    "        self.flip = preprocessing.RandomFlip(mode=self.flipmode, seed=self.seed)\n",
    "\n",
    "    @tf.function\n",
    "    def call(self, image):\n",
    "        \"\"\"apply all preprocessing steps in\n",
    "\n",
    "        Args:\n",
    "            image (tensor): numerical data of image\n",
    "\n",
    "        Returns:\n",
    "            tensor: preprocessed data\n",
    "        \"\"\"\n",
    "        image = self.rescale(image)\n",
    "        image = self.randomrotate(image)\n",
    "        image = self.randomzoom(image)\n",
    "        image = self.shift(image)\n",
    "        image = self.flip(image)\n",
    "        return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "34b48a9b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-16T05:59:11.010377Z",
     "start_time": "2021-07-16T05:59:10.997946Z"
    }
   },
   "outputs": [],
   "source": [
    "def conv_layer(filters, kernel_size, padding, strides):\n",
    "    \"\"\"Creates a convolution layer for CNNBlock\n",
    "\n",
    "    Args:\n",
    "        filters (int): number of filters in conv layer\n",
    "        kernel_size (int): kernel size for conv layer\n",
    "        padding (str): either 'same' padding or 'valid' padding\n",
    "        strides (int): strides for conv layer\n",
    "\n",
    "    Returns:\n",
    "        conv layer: returns configured conv layer for CNNBlock\n",
    "    \"\"\"\n",
    "    layer = layers.Conv2D(filters=filters, kernel_size=kernel_size, padding=padding, strides=strides, activation=layers.ReLU())\n",
    "    return layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "04b4a250",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-16T05:59:11.026280Z",
     "start_time": "2021-07-16T05:59:11.012380Z"
    }
   },
   "outputs": [],
   "source": [
    "class CNNBlock(layers.Layer):\n",
    "    def __init__(self, filters, triple=False, conv_kernel_size=(3, 3), conv_strides=(1, 1), pool_size=(2, 2), pool_strides=(2, 2), padding='same'):\n",
    "        \"\"\"block of either double (or triple) conv layers\n",
    "\n",
    "        Args:\n",
    "            filters (int): numbers of filters for the conv layers within this block\n",
    "            triple (bool, optional): whether this conv block contains double (2) or triple (3) conv layers. Defaults to False.\n",
    "            conv_strides (tuple, optional): tuple to set strides value for conv layers. Defaults to (1, 1).\n",
    "            conv_kernel_size (tuple, optional): kernel size for the conv layers in this block. Defaults to (3, 3).\n",
    "            pool_size (tuple, optional): pool size for pooling layer for this block. Defaults to (2, 2).\n",
    "            pool_strides (tuple, optional): strides value for pooling for this block. Defaults to (2, 2).\n",
    "            padding (str, optional): padding value of conv layers. Defaults to 'same'.\n",
    "        \"\"\"\n",
    "        super(CNNBlock, self).__init__()\n",
    "        self.triple = triple\n",
    "        self.pool_size = pool_size\n",
    "        self.pool_strides = pool_strides\n",
    "        self.filters = filters\n",
    "        self.conv_kernel_size = conv_kernel_size\n",
    "        self.conv_strides = conv_strides\n",
    "        self.padding = padding\n",
    "\n",
    "        self.conv1 = conv_layer(filters=self.filters, kernel_size=self.conv_kernel_size, padding=self.padding, strides=self.conv_strides)\n",
    "        self.conv2 = conv_layer(filters=self.filters, kernel_size=self.conv_kernel_size, padding=self.padding, strides=self.conv_strides)\n",
    "        if self.triple == True:\n",
    "            self.conv3 = conv_layer(filters=self.filters, kernel_size=self.conv_kernel_size, padding=self.padding, strides=self.conv_strides)\n",
    "        self.bn = layers.BatchNormalization()\n",
    "        self.maxpooling = layers.MaxPooling2D(pool_size=self.pool_size, strides=self.pool_strides)\n",
    "\n",
    "    @tf.function\n",
    "    def call(self, input_tensor, training=False):\n",
    "        \"\"\"forward propagation\n",
    "\n",
    "        Args:\n",
    "            input_tensor (input_tensor): input tensor for this data point\n",
    "            training (bool): whether to set batch normalization to training or not\n",
    "\n",
    "        Returns:\n",
    "            tensor: output of the current CNN block\n",
    "        \"\"\"\n",
    "        x = self.conv1(input_tensor)\n",
    "        x = self.conv2(x)\n",
    "        if self.triple == True:\n",
    "            x = self.conv3(x)\n",
    "        x = self.bn(x, training=training)\n",
    "        x = self.maxpooling(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ce66f7ca",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-16T05:59:11.042284Z",
     "start_time": "2021-07-16T05:59:11.028274Z"
    }
   },
   "outputs": [],
   "source": [
    "class Model(keras.Model):\n",
    "    def __init__(self, n_labels):\n",
    "        \"\"\"model build via subclassing\n",
    "\n",
    "        Args:\n",
    "            n_labels (int): amount of labels for the model to predict\n",
    "        \"\"\"\n",
    "        super(Model, self).__init__()\n",
    "        self.n_labels = n_labels\n",
    "\n",
    "        self.preprocess = Preprocess()\n",
    "        self.cnnblock1 = CNNBlock(filters=64)\n",
    "        self.cnnblock2 = CNNBlock(filters=128)\n",
    "        self.cnnblock3 = CNNBlock(filters=256, triple=True)\n",
    "        self.cnnblock4 = CNNBlock(filters=512, triple=True)\n",
    "        self.cnnblock5 = CNNBlock(filters=512, triple=True)\n",
    "        self.globalmaxpooling = layers.GlobalMaxPooling2D()\n",
    "        self.flatten = layers.Flatten()\n",
    "        self.fc = layers.Dense(4096, activation=layers.ReLU())\n",
    "        self.dropout = layers.Dropout(0.25)\n",
    "        self.outputs = layers.Dense(self.n_labels)\n",
    "\n",
    "    @tf.function\n",
    "    def call(self, input_tensor):\n",
    "        \"\"\"forward propagation for the entire model between each layer\n",
    "\n",
    "        Args:\n",
    "            input_tensor (tensor): output of the previous layer\n",
    "\n",
    "        Returns:\n",
    "            tensor: output of the previous tensor\n",
    "        \"\"\"\n",
    "        x = self.preprocess(input_tensor)\n",
    "        x = self.cnnblock1(x)\n",
    "        x = self.cnnblock2(x)\n",
    "        x = self.cnnblock3(x)\n",
    "        x = self.cnnblock4(x)\n",
    "        x = self.cnnblock5(x)\n",
    "        x = self.globalmaxpooling(x)\n",
    "        x = self.flatten(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc(x)\n",
    "        x = self.outputs(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "67bc8770",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-16T05:59:11.058297Z",
     "start_time": "2021-07-16T05:59:11.045285Z"
    }
   },
   "outputs": [],
   "source": [
    "def create_model(inp_shape, n_labels, model_name, layer_names):\n",
    "    \"\"\"creates model (input and output), name layers and compile\n",
    "\n",
    "    Args:\n",
    "        inp_shape (tuple(int)): tuple of ints, input shape\n",
    "        n_labels (int): number of labels for last layer\n",
    "        model_name (str): name of model\n",
    "        layer_names (list(str)): list of names for each layer in model\n",
    "\n",
    "    Returns:\n",
    "        model: named and configured model with input/output and named layers\n",
    "    \"\"\"\n",
    "    model = Model(n_labels=n_labels)\n",
    "\n",
    "    for i, layer in enumerate(model.layers):\n",
    "        layer._name = layer_names[i]\n",
    "    model._name = model_name\n",
    "    model.build(input_shape=(None, *inp_shape))\n",
    "\n",
    "    model.compile(loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "                  optimizer=keras.optimizers.Adam(learning_rate=1e-4),\n",
    "                  metrics=[keras.metrics.SparseCategoricalAccuracy(name='acc')])\n",
    "\n",
    "    model.summary()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9f421333",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-16T05:59:13.228915Z",
     "start_time": "2021-07-16T05:59:11.060293Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"the_first_war\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "Preprocessing (Preprocess)   multiple                  0         \n",
      "_________________________________________________________________\n",
      "CNNBlock64_Double (CNNBlock) multiple                  38976     \n",
      "_________________________________________________________________\n",
      "CNNBlock128_Double (CNNBlock multiple                  221952    \n",
      "_________________________________________________________________\n",
      "CNNBlock256_Triple (CNNBlock multiple                  1476352   \n",
      "_________________________________________________________________\n",
      "CNNBlock512_Triple_1 (CNNBlo multiple                  5901824   \n",
      "_________________________________________________________________\n",
      "CNNBlock512_Triple_2 (CNNBlo multiple                  7081472   \n",
      "_________________________________________________________________\n",
      "GlobalMaxPooling (GlobalMaxP multiple                  0         \n",
      "_________________________________________________________________\n",
      "Flatten (Flatten)            multiple                  0         \n",
      "_________________________________________________________________\n",
      "FC (Dense)                   multiple                  2101248   \n",
      "_________________________________________________________________\n",
      "Dropout (Dropout)            multiple                  0         \n",
      "_________________________________________________________________\n",
      "Outputs (Dense)              multiple                  413797    \n",
      "=================================================================\n",
      "Total params: 17,235,621\n",
      "Trainable params: 17,232,677\n",
      "Non-trainable params: 2,944\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "layer_names = tuple([\n",
    "    \"Preprocessing\",\n",
    "    \"CNNBlock64_Double\",\n",
    "    \"CNNBlock128_Double\",\n",
    "    \"CNNBlock256_Triple\",\n",
    "    \"CNNBlock512_Triple_1\",\n",
    "    \"CNNBlock512_Triple_2\",\n",
    "    \"GlobalMaxPooling\",\n",
    "    \"Flatten\",\n",
    "    \"FC\",\n",
    "    \"Dropout\",\n",
    "    \"Outputs\"\n",
    "])\n",
    "\n",
    "model = create_model(inp_shape=INPUT_SHAPE, n_labels=LABELS, model_name=MODEL_NAME, layer_names=layer_names)\n",
    "earlystopping = keras.callbacks.EarlyStopping(monitor='val_acc', patience=3, verbose=VERBOSE)\n",
    "best_checkpoint = keras.callbacks.ModelCheckpoint(filepath=MODEL_PATH,\n",
    "                                                  monitor='val_acc',\n",
    "                                                  save_best_only=True,\n",
    "                                                  save_freq='epoch',\n",
    "                                                  verbose=VERBOSE)\n",
    "callbacks = [earlystopping, best_checkpoint]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c827df7b",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-07-16T05:55:26.676Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "802/802 [==============================] - 1030s 1s/step - loss: 4.1971 - acc: 0.0901 - val_loss: 4.0370 - val_acc: 0.1009\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.10085, saving model to the_first_war\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as conv2d_layer_call_and_return_conditional_losses, conv2d_layer_call_fn, conv2d_1_layer_call_and_return_conditional_losses, conv2d_1_layer_call_fn, conv2d_2_layer_call_and_return_conditional_losses while saving (showing 5 of 135). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: the_first_war\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: the_first_war\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/30\n",
      "159/802 [====>.........................] - ETA: 12:38 - loss: 3.6892 - acc: 0.1454"
     ]
    }
   ],
   "source": [
    "train = model.fit(Train_Data,\n",
    "                  epochs=EPOCHS,\n",
    "                  verbose=VERBOSE,\n",
    "                  steps_per_epoch=len(Train_Data) // BATCH_SIZE,\n",
    "                  callbacks=callbacks,\n",
    "                  validation_data=Val_Data,\n",
    "                  validation_steps=len(Val_Data) // BATCH_SIZE,\n",
    "                  use_multiprocessing=True,\n",
    "                  workers=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3db94bdf",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-07-16T05:55:26.678Z"
    }
   },
   "outputs": [],
   "source": [
    "test = model.evaluate(Test_Data, steps=len(Test_Data) // BATCH_SIZE, workers=-1, use_multiprocessing=True, verbose=VERBOSE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ca290e0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
